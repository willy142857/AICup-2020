{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitdmcondaf1b27da96c0b455a9810335c0be0c477",
   "display_name": "Python 3.8.5 64-bit ('dm': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Get bert-crf output"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ner_path = '../bert-crf/bert-crf-model/test_predictions.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from preproc import get_testing_data\n",
    "\n",
    "from utils import timestamp\n",
    "\n",
    "predictions = pickle.load(open(t_ner_path, 'rb'))\n",
    "data = get_testing_data('../data/test_5.txt')\n",
    "predictions = [p for prediction in predictions for p in prediction]\n",
    "\n",
    "output = \"article_id\\tstart_position\\tend_position\\tentity_text\\tentity_type\\n\"\n",
    "i = 0\n",
    "for test_id in range(len(data)):\n",
    "    pos = 0\n",
    "    start_pos = None\n",
    "    end_pos = None\n",
    "    entity_text = None\n",
    "    entity_type = None\n",
    "    for pred_id in range(len(data[test_id])):\n",
    "        if data[test_id][pred_id] == ' ':\n",
    "            pos += 1\n",
    "            continue\n",
    "\n",
    "        if predictions[i][0] == 'B':\n",
    "            start_pos = pos\n",
    "            entity_type = predictions[i][2:]\n",
    "        elif start_pos is not None and predictions[i][0] == 'I' and predictions[i+1][0] == 'O':\n",
    "            end_pos = pos\n",
    "            entity_text = ''.join([data[test_id][position][0]\n",
    "                                    for position in range(start_pos, end_pos+1)])\n",
    "\n",
    "            tokens = [str(test_id), str(start_pos), str(\n",
    "                end_pos+1), entity_text, entity_type]\n",
    "            line = '\\t'.join(tokens)\n",
    "            output += line + '\\n'\n",
    "\n",
    "            start_pos = None\n",
    "        pos += 1\n",
    "        i += 1\n",
    "with open(f'outputs-tsv/output-crf.tsv', 'w', encoding='utf-8') as f:\n",
    "    f.write(output)"
   ]
  },
  {
   "source": [
    "## Merge bert and bert-crf outputs"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bert_path = 'outputs-tsv/output-bert.tsv'\n",
    "bert_crf_path = 'outputs-tsv/output-crf.tsv'\n",
    "\n",
    "a_df = pd.read_csv(bert_path, sep='\\t')\n",
    "b_df = pd.read_csv(bert_crf_path, sep='\\t')\n",
    "\n",
    "a_df['src'] = 'bert'\n",
    "b_df['src'] = 'bert-crf'\n",
    "df = pd.concat([a_df, b_df.query(\"entity_type != 'ID'\")])\n",
    "df = df.drop_duplicates(subset=['article_id', 'start_position', 'end_position', 'entity_text', 'entity_type']).reset_index(drop=True)\n",
    "df = df.sort_values(by=['article_id', 'start_position', 'end_position'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = df.groupby('article_id')['start_position'].apply(list)\n",
    "end = df.groupby('article_id')['end_position'].apply(list)\n",
    "\n",
    "for s, e in zip(start, end):\n",
    "    for i, v in enumerate(e):\n",
    "        s.insert(2*i+1, v) \n",
    "\n",
    "ret = pd.DataFrame() \n",
    "for idx, s in enumerate(start):\n",
    "    for i in range(len(s)-1):\n",
    "        if s[i] >= s[i+1]:\n",
    "            start_pos = s[i+1]\n",
    "            end_pos = s[i]\n",
    "            temp = df.query(\"article_id == @idx and (start_position == @start_pos or end_position == @end_pos) and src == 'bert'\")\n",
    "            ret = ret.append(temp)\n",
    "\n",
    "df.drop(ret.index, inplace=True)\n",
    "df.drop(columns=['src']).to_csv('outputs-tsv/result.tsv', sep='\\t', index=False)"
   ]
  }
 ]
}